#!/usr/bin/env python3
"""GitHub Contributions Statistics Script

## æ ¸å¿ƒåŠŸèƒ½
- ç»Ÿè®¡æ‰€æœ‰ä»“åº“çš„è´¡çŒ®ï¼ˆadditions/deletionsã€imagesæ•°é‡ï¼‰
- æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œé¿å…é‡å¤åˆ†æå·²å¤„ç†çš„ commits
- æ”¯æŒ Fork ä»“åº“ï¼ˆè‡ªåŠ¨åˆ†æä¸Šæ¸¸ä»“åº“ï¼‰
- è‡ªåŠ¨æ›´æ–° README.md ç»Ÿè®¡æ•°æ®å’Œæ—¶é—´

## æ•°æ®æº
- æœ¬åœ° git logï¼šå®Œæ•´å†å²æ•°æ®
- GitHub APIï¼šæœ€æ–°æ•°æ®ï¼ˆæœ€å¤š 1000 ä¸ª commitsï¼‰
- æ™ºèƒ½åˆå¹¶ï¼šå–ä¸¤è€…ä¼˜åŠ¿ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§

## ç¼“å­˜æœºåˆ¶
æ¯ä¸ªä»“åº“ä¸€ä¸ª JSON æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- å…ƒæ•°æ®ï¼šæ€» commits æ•°ã€æ€» additions/deletions æ•°ã€æ€» images æ•°
- è¯¦ç»†æ•°æ®ï¼šæ¯ä¸ª commit çš„ç»Ÿè®¡æ•°æ®

## æ›´æ–°ç­–ç•¥
- åªæœ‰è¿è¡Œè„šæœ¬æ—¶æ‰æ›´æ–°æ•°æ®
- ä½¿ç”¨æ­£åˆ™åŒ¹é…æ›¿æ¢ï¼Œä¿æŒ README.md åŸæœ‰æ ¼å¼
- æ°¸ä¹…ä¿å­˜å†å²æ•°æ®ï¼Œæ™ºèƒ½æ¸…ç†è¿‡æœŸç¼“å­˜
"""

import os
import subprocess
import json
import re
import shutil
import argparse
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Optional, Tuple, List, Dict, cast

# ============================================================================
# ç±»å‹å®šä¹‰
# ============================================================================

FileData = Dict[str, str | int]
AuthorData = Dict[str, str]
CommitDetailData = Dict[str, AuthorData]
CommitData = Dict[str, str | int | FileData | CommitDetailData | List[FileData]]
CacheData = Dict[str, List[CommitData]]
RepoInfo = Dict[str, str | bool | Dict[str, str] | None]
StatsData = Dict[str, int]

# ============================================================================
# å¸¸é‡å®šä¹‰
# ============================================================================

GITHUB_API = "https://api.github.com"
SEPARATOR_LENGTH = 60
MAX_API_PAGES = 10
PER_PAGE = 100
PROGRESS_INTERVAL = 10
IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.webp', '.ico']
README_FILE_PATH = Path(__file__).parent.parent / "README.md"
CACHE_DIR = Path(__file__).parent / "stats_cache"

# æ—¶é—´å’Œæ ¼å¼å¸¸é‡
TIME_FORMAT = "%Y-%m-%d %H:%M:%S UTC+8"
TIME_PATTERN = r'(Last updated: )\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}( UTC\+8)?'
STATS_PATTERN = r'(â•additions: )\d+( â–deletions: )\d+( ğŸ–¼ï¸images: )\d+'

# å ä½ç¬¦æ˜ å°„
PLACEHOLDER_MAPPINGS = {
    'ORIGIN_USERNAME': 'ORIGIN_USERNAME',
    'UPSTREAM_USERNAME': 'UPSTREAM_USERNAME',
    'TOTAL_ADDITIONS': 'total_additions',
    'TOTAL_DELETIONS': 'total_deletions',
    'TOTAL_IMAGES': 'total_images',
    'LAST_UPDATED': 'current_time'
}


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def get_default_from_readme(var_name: str) -> Optional[str]:
    """ä» README.md ä¸­è¯»å–é»˜è®¤çš„ç”¨æˆ·åå˜é‡"""
    if not README_FILE_PATH.exists():
        return None

    try:
        with open(README_FILE_PATH, 'r', encoding='utf-8') as f:
            content = f.read()

        # æŸ¥æ‰¾å˜é‡å®šä¹‰
        pattern = rf'{var_name} = ([^\n\r]+)'
        match = re.search(pattern, content)
        if match:
            return match.group(1).strip()
    except Exception:
        pass

    return None


# ============================================================================
# é…ç½®
# ============================================================================

ORIGIN_USERNAME = (
    os.environ.get("ORIGIN_USERNAME") or
    get_default_from_readme("ORIGIN_USERNAME") or
    ""
)
UPSTREAM_USERNAME = (
    os.environ.get("UPSTREAM_USERNAME") or
    get_default_from_readme("UPSTREAM_USERNAME") or
    ""
)
TOKEN = os.environ.get("GH_TOKEN")


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

class Colors:
    """ç»ˆç«¯é¢œè‰²å®šä¹‰"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    NC = '\033[0m'

def print_color(message: str, color: str = Colors.NC) -> None:
    """å½©è‰²è¾“å‡º"""
    print(f"{color}{message}{Colors.NC}")

def print_separator(title: str | None = None, color: str = Colors.GREEN) -> None:
    """æ‰“å°åˆ†éš”çº¿ï¼Œå¯é€‰æ ‡é¢˜"""
    separator = "=" * SEPARATOR_LENGTH
    print_color(separator, color)
    if title:
        print_color(title, color)
        print_color(separator, color)

def handle_error(operation: str, error: Exception, return_value: str | None = None) -> str | None:
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†"""
    print_color(f"âŒ {operation}å¤±è´¥: {error}", Colors.RED)
    return return_value


def is_image_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡"""
    return any(filename.lower().endswith(ext) for ext in IMAGE_EXTENSIONS)


def print_stats_summary(additions: int, deletions: int, images: int, include_images: bool = True, prefix: str = "") -> None:
    """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
    print_color(f"{prefix}âœ… ä»£ç è´¡çŒ®: +{additions} additions, -{deletions} deletions", Colors.GREEN)
    if include_images:
        print_color(f"{prefix}âœ… å›¾ç‰‡è´¡çŒ®: {images} images", Colors.GREEN)

def run_command(cmd: str, cwd: Optional[str] = None) -> Tuple[str, int]:
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            cwd=cwd
        )
        return result.stdout.strip(), result.returncode
    except Exception as e:
        print_color(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}", Colors.RED)
        return "", 1

def replace_placeholders(content: str, replacements: Dict[str, str]) -> str:
    """é€šç”¨å ä½ç¬¦æ›¿æ¢å‡½æ•°"""
    for placeholder, value in replacements.items():
        content = content.replace(f'{{{{{placeholder}}}}}', str(value))
    return content

def update_variable_definition(content: str, var_name: str, var_value: str) -> str:
    """é€šç”¨å˜é‡å®šä¹‰æ›´æ–°å‡½æ•°"""
    pattern = rf'({var_name} = )([^\n\r]+)'
    if re.search(pattern, content):
        content = re.sub(pattern, f'\\1{var_value}', content)
        print_color(f"âœ… å·²æ›´æ–° {var_name} å®šä¹‰ä¸º: {var_value}", Colors.GREEN)
    return content

def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
    china_tz = timezone(timedelta(hours=8))
    return datetime.now(china_tz).strftime(TIME_FORMAT)

def calculate_cache_statistics(cache_data: CacheData) -> Tuple[int, int, int, int]:
    """è®¡ç®—ç¼“å­˜æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯

    è¿”å›: (total_commits, total_additions, total_deletions, total_images)
    """
    total_commits = 0
    total_additions = 0
    total_deletions = 0
    total_images = 0

    for _, commits in cache_data.items():
        commits_list: List[CommitData] = commits
        # æ–°æ ¼å¼ï¼šæ•°ç»„ç»“æ„
        total_commits += len(commits_list)
        for commit in commits_list:
            commit_dict = cast(Dict[str, str | int], commit)
            additions = commit_dict.get('additions', 0)
            deletions = commit_dict.get('deletions', 0)
            images = commit_dict.get('images', 0)
            total_additions += additions if isinstance(additions, int) else 0
            total_deletions += deletions if isinstance(deletions, int) else 0
            total_images += images if isinstance(images, int) else 0

    return total_commits, total_additions, total_deletions, total_images


def sort_and_reindex_commits(cache_data: CacheData) -> CacheData:
    """å¯¹ç¼“å­˜æ•°æ®è¿›è¡Œæ’åºå’Œé‡æ–°ç¼–å·"""
    sorted_cache_data: CacheData = {}

    for repo_name, commits in cache_data.items():
        # æŒ‰ timestamp ä»æ—§åˆ°æ–°æ’åºï¼ˆè€çš„åœ¨å‰ï¼Œæ–°çš„åœ¨åï¼‰
        sorted_commits: List[CommitData] = sorted(commits, key=lambda x: str(x.get('timestamp', '')))

        # é‡æ–°ç¼–å· indexï¼ˆä» 1 å¼€å§‹ï¼‰
        for idx, commit in enumerate(sorted_commits, start=1):
            commit['index'] = idx

        sorted_cache_data[repo_name] = sorted_commits

    return sorted_cache_data

# ============================================================================
# ç¼“å­˜ç®¡ç†
# ============================================================================

def load_cache(repo_name: str) -> CacheData:
    """åŠ è½½æŒ‡å®šä»“åº“çš„ç¼“å­˜æ•°æ®"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_file = CACHE_DIR / f"{repo_name}.json"

    try:
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
            print_color(f"ğŸ’¾ å·²åŠ è½½ç¼“å­˜: {cache_file}", Colors.GREEN)

            metadata = cache_data.get('_metadata', {})
            print_color(f"   ç¼“å­˜åŒ…å« {metadata.get('total_commits', 0)} ä¸ªcommits", Colors.NC)
            return cache_data.get('data', {})
    except (json.JSONDecodeError, IOError) as e:
        print_color(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}", Colors.YELLOW)
        return {}


def save_cache(repo_name: str, cache_data: CacheData) -> bool:
    """ä¿å­˜æŒ‡å®šä»“åº“çš„ç¼“å­˜æ•°æ®

    åŠŸèƒ½ï¼š
    - æŒ‰æ—¶é—´æˆ³æ’åº commitsï¼ˆä»æ—§åˆ°æ–°ï¼‰
    - é‡æ–°ç¼–å· commit indexï¼ˆä» 1 å¼€å§‹ï¼‰
    - ç»Ÿè®¡æ€» commits æ•°ã€æ€»å¢åˆ è¡Œæ•°å’Œæ€»å›¾ç‰‡æ•°
    - ä¿å­˜ä¸ºå¸¦ metadata çš„ JSON æ ¼å¼

    å‚æ•°ï¼š
    - repo_name: ä»“åº“åç§°
    - cache_data: ç¼“å­˜æ•°æ®å­—å…¸

    JSON è¾“å‡ºæ ¼å¼ï¼š
    {
      "_metadata": {
        "total_commits": int,    // æ€» commit æ•°
        "total_additions": int,  // æ€»å¢åŠ è¡Œæ•°
        "total_deletions": int,  // æ€»åˆ é™¤è¡Œæ•°
        "total_images": int      // æ€»å›¾ç‰‡æ•°
      },
      "data": { ... }            // commit æ•°æ®
    }
    """
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_file = CACHE_DIR / f"{repo_name}.json"

    try:
        # æ’åºå’Œé‡æ–°ç¼–å·
        sorted_cache_data = sort_and_reindex_commits(cache_data)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_commits, total_additions, total_deletions, total_images = calculate_cache_statistics(sorted_cache_data)

        cache_data_with_metadata: Dict[str, Dict[str, int] | CacheData] = {
            '_metadata': {
                'total_commits': total_commits,
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'total_images': total_images
            },
            'data': sorted_cache_data
        }

        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data_with_metadata, f, indent=2, ensure_ascii=False)

        print_color(f"âœ… ç¼“å­˜å·²ä¿å­˜: {cache_file}", Colors.GREEN)
        print_color(f"   commits: {total_commits}", Colors.NC)
        print_color(f"   additions: {total_additions}", Colors.NC)
        print_color(f"   deletions: {total_deletions}", Colors.NC)
        print_color(f"   images: {total_images}", Colors.NC)
        return True
    except Exception as e:
        print_color(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}", Colors.RED)
        return False


def extract_sha_from_cache_item(item: str | CommitData, is_list_format: bool) -> str:
    """ä»ç¼“å­˜é¡¹ä¸­æå–SHAå€¼"""
    if is_list_format:
        if isinstance(item, dict):
            url = item.get('url', '')
            if isinstance(url, str):
                return url.split('/')[-1] if url else ''
        return ''
    else:
        return item if isinstance(item, str) else ''


def should_preserve_commit(cached_commit_time: str, oldest_current_time: Optional[str]) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿ç•™commitï¼ˆæ°¸ä¹…å†å²æ•°æ®ï¼‰"""
    if not oldest_current_time or not cached_commit_time:
        return False
    return cached_commit_time < oldest_current_time


def clean_stale_cache(cache_data: CacheData, current_commits_with_data: List[CommitData], repo_key: str) -> CacheData:
    """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜ï¼ˆæ£€æµ‹å˜åŸºç­‰å¯¼è‡´çš„commitå“ˆå¸Œå˜åŒ–ï¼‰

    ç­–ç•¥ï¼š
    1. åªæ¸…é™¤åœ¨å½“å‰åˆå¹¶æ•°æ®ä¸­æ¶ˆå¤±çš„ commitsï¼ˆå¯èƒ½è¢«å˜åŸºã€å‹ç¼©æˆ–é‡å†™ï¼‰
    2. æ°¸ä¹…ä¿å­˜æ¯”å½“å‰æœ€è€ commit è¿˜è¦ä¹…è¿œçš„ç¼“å­˜æ•°æ®ï¼ˆæŸ¥ä¸åˆ°çš„å†å²ï¼‰
    3. æ›´æ–°æ–°çš„ commits åˆ°ç¼“å­˜

    å‚æ•°ï¼š
    - current_commits_with_data: å½“å‰åˆå¹¶åçš„å®Œæ•´ commit å¯¹è±¡åˆ—è¡¨ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    """
    if repo_key not in cache_data:
        return cache_data

    # è·å–å½“å‰æ•°æ®çš„ sha é›†åˆå’Œæœ€è€çš„æ—¶é—´æˆ³
    current_commit_set: set[str] = set()
    oldest_current_time: str | None = None

    for commit in current_commits_with_data:
        sha = commit.get('sha')
        if isinstance(sha, str):
            current_commit_set.add(sha)

        # è·å– commit æ—¶é—´æˆ³
        commit_dict = commit.get('commit', {})
        if isinstance(commit_dict, dict):
            author_dict = commit_dict.get('author', {})
            if isinstance(author_dict, dict):
                commit_time = author_dict.get('date', '')
                if oldest_current_time is None or commit_time < oldest_current_time:
                    oldest_current_time = commit_time

    # è·å–ç¼“å­˜ä¸­çš„SHAé›†åˆ
    cached_shas: set[str] = set()

    # æ–°æ ¼å¼ï¼šæ•°ç»„ç»“æ„
    for item in cache_data[repo_key]:
        sha = extract_sha_from_cache_item(item, True)
        if sha:
            cached_shas.add(sha)

    # æ‰¾å‡ºåœ¨å½“å‰åˆå¹¶æ•°æ®ä¸­æ¶ˆå¤±çš„ commits
    stale_commits: set[str] = cached_shas - current_commit_set

    if stale_commits:
        print_color(f"    ğŸ§¹ æ£€æµ‹åˆ° {len(stale_commits)} ä¸ªæ¶ˆå¤±çš„commits", Colors.YELLOW)
        print_color(f"       åŸå› ï¼šå¯èƒ½è¢«å˜åŸºã€å‹ç¼©æˆ–é‡å†™", Colors.YELLOW)

        deleted_count = 0
        preserved_count = 0

        # æ–°æ ¼å¼ï¼šè¿‡æ»¤æ•°ç»„
        new_cache_list: List[CommitData] = []
        for item in cache_data[repo_key]:
            sha = extract_sha_from_cache_item(item, True)
            cached_commit_time = item.get('timestamp', '')
            if not isinstance(cached_commit_time, str):
                cached_commit_time = str(cached_commit_time)

            # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ é™¤
            if sha in stale_commits:
                if should_preserve_commit(cached_commit_time, oldest_current_time):
                    # ä¿ç•™æ°¸ä¹…å†å²æ•°æ®
                    new_cache_list.append(item)
                    preserved_count += 1
                else:
                    # åˆ é™¤åœ¨å½“å‰æ•°æ®èŒƒå›´å†…æ¶ˆå¤±çš„ commits
                    deleted_count += 1
            else:
                new_cache_list.append(item)

        cache_data[repo_key] = new_cache_list

        print_color(f"    âœ… å·²æ¸…é™¤ {deleted_count} ä¸ªè¿‡æœŸçš„commitç¼“å­˜åŠå…¶ç»Ÿè®¡æ•°æ®", Colors.GREEN)
        if preserved_count > 0:
            print_color(f"    â„¹ï¸  ä¿ç•™ {preserved_count} ä¸ªæ°¸ä¹…å†å²æ•°æ®ï¼ˆæ¯”å½“å‰æœ€è€æ•°æ®æ›´ä¹…è¿œï¼‰", Colors.NC)

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦ä¸ºç©ºå¹¶æ¸…ç†
        if not cache_data[repo_key]:
            del cache_data[repo_key]
            print_color(f"    â„¹ï¸  ä»“åº“ç¼“å­˜å·²æ¸…ç©º", Colors.NC)
    else:
        print_color(f"    âœ… ç¼“å­˜æ•°æ®å®Œæ•´ï¼Œæ— æ¶ˆå¤±çš„commits", Colors.GREEN)

    return cache_data


# ============================================================================
# GitHub API æ“ä½œ
# ============================================================================

def get_repos() -> List[RepoInfo]:
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰ä»“åº“ï¼ˆåŒ…æ‹¬å…¬å¼€å’Œç§æœ‰ä»“åº“ï¼‰"""
    print_color("ğŸ“¡ è·å–æ‰€æœ‰ä»“åº“åˆ—è¡¨...", Colors.YELLOW)

    # ä½¿ç”¨ curl è·å–ä»“åº“åˆ—è¡¨
    curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{GITHUB_API}/users/{ORIGIN_USERNAME}/repos?per_page={PER_PAGE}&type=all"'
    output, returncode = run_command(curl_cmd)

    if returncode != 0:
        print_color("âŒ è·å–ä»“åº“åˆ—è¡¨å¤±è´¥", Colors.RED)
        return []

    # è§£æ JSON
    try:
        parsed_data: List[Dict[str, str | bool | Dict[str, str] | None]] = json.loads(output)

        repos: List[RepoInfo] = []
        for repo in parsed_data:
            repo_info: RepoInfo = repo
            repos.append(repo_info)

        print_color(f"âœ… è·å–åˆ° {len(repos)} ä¸ªä»“åº“", Colors.GREEN)
        for repo in repos:
            repo_name = repo.get('name', 'Unknown')
            is_fork = repo.get('fork', False)
            print_color(f"   - {repo_name} ({'Fork' if is_fork else 'åŸåˆ›'})", Colors.NC)
        return repos
    except json.JSONDecodeError as e:
        print_color(f"âŒ JSON è§£æå¤±è´¥: {e}", Colors.RED)
        print_color(f"æ•°æ®å†…å®¹: {output[:500]}", Colors.RED)
        return []


def get_upstream_repo(repo: RepoInfo) -> Tuple[Optional[str], Optional[str]]:
    """è·å– fork ä»“åº“çš„ä¸Šæ¸¸ä»“åº“ä¿¡æ¯"""
    is_fork = repo.get('fork')
    if not isinstance(is_fork, bool) or not is_fork:
        return None, None

    upstream_info = repo.get('source') or repo.get('parent')
    if isinstance(upstream_info, dict):
        upstream_dict: Dict[str, str | Dict[str, str]] = cast(Dict[str, str | Dict[str, str]], upstream_info)
        owner_dict = upstream_dict.get('owner')
        if isinstance(owner_dict, dict):
            upstream_owner = owner_dict.get('login')
            upstream_name = upstream_dict.get('name')
            if isinstance(upstream_owner, str) and isinstance(upstream_name, str):
                return upstream_owner, upstream_name
    return None, None


# ============================================================================
# Commits æ•°æ®è·å–
# ============================================================================

def get_commits_from_git_log(repo_path: str, username: str, default_branch: str) -> Optional[List[CommitData]]:
    """ä»æœ¬åœ° git log è·å–ç”¨æˆ·çš„æ‰€æœ‰ commitsï¼ˆå®Œæ•´å†å²ï¼‰"""
    git_cmd = f'git log origin/{default_branch} --author="{username}" --format="%H"'
    output, returncode = run_command(git_cmd, cwd=repo_path)

    if returncode == 0:
        commit_hashes = [h.strip() for h in output.split('\n') if h.strip()]
        all_commits: List[CommitData] = [{'sha': h} for h in commit_hashes]
        print_color(f"    â„¹ï¸  git log è·å– {len(all_commits)} ä¸ªcommits", Colors.NC)
        return all_commits
    else:
        print_color(f"    âš ï¸  git log å¤±è´¥", Colors.YELLOW)
        return None


def get_commits_from_api(owner: str, repo_name: str, username: str, default_branch: str = 'main', max_pages: int = MAX_API_PAGES) -> List[CommitData]:
    """ä» GitHub API è·å–ç”¨æˆ·çš„æœ€è¿‘ commitsï¼ˆåˆ†é¡µï¼Œæœ€å¤š 10 é¡µï¼‰

    åªè·å–é»˜è®¤åˆ†æ”¯çš„ commitsï¼Œé¿å…ç»Ÿè®¡æœªåˆå¹¶ PR çš„ commits
    å¾ˆä¹…ä»¥å‰çš„ commits ä»ç¼“å­˜è¯»å–
    """
    page = 1
    per_page = PER_PAGE
    all_commits: List[CommitData] = []

    while page <= max_pages:
        api_url = f"{GITHUB_API}/repos/{owner}/{repo_name}/commits?author={username}&sha={default_branch}&per_page={per_page}&page={page}"
        print_color(f"    ğŸ” è·å–commits (ç¬¬{page}é¡µ)...", Colors.NC)

        curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{api_url}"'
        output, returncode = run_command(curl_cmd)

        if returncode != 0:
            print_color("    âŒ APIè°ƒç”¨å¤±è´¥", Colors.RED)
            return all_commits if all_commits else []

        try:
            parsed_commits: List[Dict[str, str | int | FileData | CommitDetailData | List[FileData]]] = json.loads(output)
            if not parsed_commits:
                break

            for commit in parsed_commits:
                commit_data: CommitData = commit
                all_commits.append(commit_data)

            print_color(f"    ğŸ“Š å·²è·å– {len(all_commits)} ä¸ªcommits", Colors.NC)

            if len(parsed_commits) < per_page:
                break

            page += 1

        except json.JSONDecodeError as e:
            print_color(f"    âŒ JSON è§£æå¤±è´¥: {e}", Colors.RED)
            return all_commits if all_commits else []

    if page > max_pages:
        print_color(f"    â„¹ï¸  å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({max_pages} é¡µ)ï¼Œå…± {len(all_commits)} ä¸ªcommits", Colors.NC)
        print_color(f"    â„¹ï¸  æ›´ä¹…ä»¥å‰çš„ commits å°†ä»ç¼“å­˜è¯»å–", Colors.NC)

    return all_commits


def merge_commits(git_commits: Optional[List[CommitData]], api_commits: Optional[List[CommitData]]) -> List[CommitData]:
    """åˆå¹¶ git log å’Œ API çš„ commits æ•°æ®

    ç­–ç•¥ï¼ˆæ•°æ®ç›¸äº¤ï¼‰ï¼š
    1. åŒæ—¶ä½¿ç”¨ git logï¼ˆå®Œæ•´å†å²ï¼‰å’Œ APIï¼ˆæœ€è¿‘ 10 é¡µï¼‰çš„æ•°æ®
    2. å¯¹äºç›¸åŒçš„ commitsï¼šæ¯”è¾ƒæ—¶é—´æˆ³ï¼Œè°çš„æ•°æ®æ›´æ–°å°±ç”¨è°çš„
    3. å¯¹äºä¸åŒçš„ commitsï¼šä¿ç•™å„è‡ªçš„æ•°æ®
    4. ç»“æœï¼šgit log çš„è€æ•°æ® + API çš„æ–°æ•°æ® + æœ€æ–°çš„æ›´æ–°

    è¿™æ ·å¯ä»¥å¤„ç†ï¼š
    - git log æ²¡æ›´æ–°çš„æƒ…å†µï¼ˆç”¨ API çš„æ–°æ•°æ®ï¼‰
    - API é™æµæˆ–æ²¡æ›´æ–°çš„æƒ…å†µï¼ˆç”¨ git log çš„æ•°æ®ï¼‰
    - ä¸¤ä¸ªæ•°æ®æºéƒ½æœ‰å„è‡ªç‹¬ç‰¹çš„æ•°æ®ï¼ˆéƒ½ä¿ç•™ï¼‰
    """
    git_count = len(git_commits) if git_commits else 0
    api_count = len(api_commits) if api_commits else 0

    print_color(f"    ğŸ“Š åˆå¹¶æ•°æ®æº:", Colors.YELLOW)
    print_color(f"       - git log: {git_count} ä¸ªcommitsï¼ˆå®Œæ•´å†å²ï¼‰", Colors.NC)
    print_color(f"       - API: {api_count} ä¸ªcommitsï¼ˆæœ€å¤š 10 é¡µï¼‰", Colors.NC)

    if not git_commits and not api_commits:
        print_color(f"    âŒ ä¸¤ä¸ªæ•°æ®æºéƒ½æ— æ•°æ®", Colors.RED)
        return []

    if not git_commits:
        print_color(f"    âœ… ä»…ä½¿ç”¨ API æ•°æ®", Colors.GREEN)
        return api_commits or []

    if not api_commits:
        print_color(f"    âœ… ä»…ä½¿ç”¨ git log æ•°æ®", Colors.GREEN)
        return git_commits or []

    # æ„å»º commit æ˜ å°„ï¼ˆsha -> commit å¯¹è±¡ï¼‰
    git_map: Dict[str, CommitData] = {str(c.get('sha')): c for c in git_commits if c.get('sha')}
    api_map: Dict[str, CommitData] = {str(c.get('sha')): c for c in api_commits if c.get('sha')}

    # æ‰¾å‡ºç›¸åŒå’Œä¸åŒçš„ commits
    git_shas = set(git_map.keys())
    api_shas = set(api_map.keys())
    common_shas = git_shas & api_shas
    git_only_shas = git_shas - api_shas
    api_only_shas = api_shas - git_shas

    print_color(f"    ğŸ“Š æ•°æ®åˆ†æ:", Colors.YELLOW)
    print_color(f"       - ç›¸åŒ commits: {len(common_shas)}", Colors.NC)
    print_color(f"       - ä»…åœ¨ git log: {len(git_only_shas)}", Colors.NC)
    print_color(f"       - ä»…åœ¨ API: {len(api_only_shas)}", Colors.NC)

    # åˆå¹¶ç»“æœ
    merged: Dict[str, CommitData] = {}

    #1. å¤„ç†ç›¸åŒçš„ commitsï¼šæ¯”è¾ƒæ—¶é—´æˆ³ï¼Œè°çš„æ–°ç”¨è°çš„
    for sha in common_shas:
        git_commit = git_map[sha]
        api_commit = api_map[sha]

        git_commit_dict = git_commit.get('commit', {})
        api_commit_dict = api_commit.get('commit', {})
        if isinstance(git_commit_dict, dict) and isinstance(api_commit_dict, dict):
            git_author_dict = git_commit_dict.get('author', {})
            api_author_dict = api_commit_dict.get('author', {})
            if isinstance(git_author_dict, dict) and isinstance(api_author_dict, dict):
                git_time = git_author_dict.get('date', '')
                api_time = api_author_dict.get('date', '')
                if api_time > git_time:
                    # API æ•°æ®æ›´æ–°
                    merged[sha] = api_commit
                else:
                    # git log æ•°æ®æ›´æ–°æˆ–ç›¸åŒ
                    merged[sha] = git_commit
            else:
                # Fallback: prefer API commit if author dict check fails
                merged[sha] = api_commit
        else:
            # Fallback: prefer API commit if commit dict check fails
            merged[sha] = api_commit

    # 2. ä¿ç•™ git log ç‹¬æœ‰çš„ commitsï¼ˆè€æ•°æ®ï¼‰
    for sha in git_only_shas:
        merged[sha] = git_map[sha]

    # 3. ä¿ç•™ API ç‹¬æœ‰çš„ commitsï¼ˆæ–°æ•°æ®ï¼‰
    for sha in api_only_shas:
        merged[sha] = api_map[sha]

    result: List[CommitData] = list(merged.values())
    print_color(f"    âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(result)} ä¸ªcommits", Colors.GREEN)
    return result


# ============================================================================
# Commits åˆ†æ
# ============================================================================

def analyze_commits(repo_path: str, owner: str, repo_name: str, username: str, include_images: bool = True) -> Tuple[int, int, int]:
    """åŒæ—¶åˆ†æä»£ç è¡Œæ•°å’Œå›¾ç‰‡è´¡çŒ®

    è¿”å›: (additions, deletions, total_images)
    """
    print_color(f"    ğŸ“Š å¼€å§‹åˆ†æcommits...", Colors.YELLOW)

    # åŠ è½½ç¼“å­˜
    cache_data = load_cache(repo_name)

    # è·å– commitsï¼ˆåŒæ—¶å°è¯• git log å’Œ APIï¼Œé€‰æ‹©æœ€æ–°çš„ï¼‰
    git_commits = None
    api_commits = None
    default_branch = 'main'

    # 1. å°è¯•ä»æœ¬åœ° git log è·å–
    if repo_path:
        git_cmd = 'git symbolic-ref refs/remotes/origin/HEAD | sed "s@^refs/remotes/origin/@@"'
        output, returncode = run_command(git_cmd, cwd=repo_path)
        default_branch = output.strip() if returncode == 0 else 'main'

        print_color(f"    â„¹ï¸  é»˜è®¤åˆ†æ”¯: {default_branch}", Colors.NC)
        git_commits = get_commits_from_git_log(repo_path, username, default_branch)

    # 2. å°è¯•ä» API è·å–
    api_commits = get_commits_from_api(owner, repo_name, username, default_branch)

    # 3. åˆå¹¶ä¸¤ä¸ªæ•°æ®æºï¼ˆæ•°æ®ç›¸äº¤ç­–ç•¥ï¼‰
    all_commits = merge_commits(git_commits, api_commits)

    if not all_commits:
        print_color(f"    â„¹ï¸  æœªæ‰¾åˆ°commits", Colors.NC)
        return 0, 0, 0

    total_commits = len(all_commits)
    print_color(f"    ğŸ“Š æœ€ç»ˆä½¿ç”¨ {total_commits} ä¸ªcommits", Colors.NC)

    # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆä¼ å…¥å®Œæ•´çš„ commit å¯¹è±¡ä»¥è·å–æ—¶é—´æˆ³ï¼‰
    cache_data = clean_stale_cache(cache_data, all_commits, repo_name)

    # ç»Ÿè®¡æ•°æ®
    total_additions = 0
    total_deletions = 0
    total_images = 0
    processed = 0
    cache_hits = 0
    cache_misses = 0

    for commit in all_commits:
        sha = commit.get('sha')
        if not sha:
            continue

        processed += 1
        if processed % PROGRESS_INTERVAL == 0:
            print_color(f"    ğŸ“Š å¤„ç†ä¸­: {processed}/{total_commits} ({processed*100//total_commits}%)", Colors.NC)

        # æ£€æŸ¥ç¼“å­˜
        commit_url = f"https://github.com/{owner}/{repo_name}/commit/{sha}"
        cached_data = None
        if repo_name in cache_data:
            # æ–°æ ¼å¼ï¼šæ•°ç»„ç»“æ„
            for item in cache_data[repo_name]:
                if item.get('url') == commit_url:
                    cached_data = item
                    break

        if cached_data:
            cached_additions = cached_data.get('additions', 0)
            cached_deletions = cached_data.get('deletions', 0)
            cached_images = cached_data.get('images', 0)
            if isinstance(cached_additions, int):
                total_additions += cached_additions
            if isinstance(cached_deletions, int):
                total_deletions += cached_deletions
            if isinstance(cached_images, int):
                total_images += cached_images
            cache_hits += 1
            continue

        cache_misses += 1
        commit_data: CommitData = {}

        # è·å– commit è¯¦æƒ…
        if repo_path:
            # æœ¬åœ°ä»“åº“ç”¨ git show
            # å…ˆè·å–æ–‡ä»¶çŠ¶æ€ï¼ˆA=added, M=modified, D=deleted ç­‰ï¼‰
            git_cmd = f'git show --name-status --pretty="" {sha}'
            status_output, returncode = run_command(git_cmd, cwd=repo_path)

            # å†è·å–æ–‡ä»¶çš„è¡Œæ•°ç»Ÿè®¡
            git_cmd = f'git show --numstat --pretty="" {sha}'
            numstat_output, returncode = run_command(git_cmd, cwd=repo_path)

            if returncode == 0:
                commit_data['files'] = []

                # æ„å»ºçŠ¶æ€æ˜ å°„
                status_map: Dict[str, str] = {}
                for line in status_output.split('\n'):
                    if line.strip():
                        parts = line.split('\t')
                        if len(parts) >= 2:
                            status = parts[0]  # A, M, D ç­‰
                            filename = parts[1]
                            status_map[filename] = status

                # å¤„ç†è¡Œæ•°ç»Ÿè®¡
                for line in numstat_output.split('\n'):
                    if line.strip():
                        parts = line.split('\t')
                        if len(parts) >= 3:
                            try:
                                add_count = int(parts[0]) if parts[0] != '-' else 0
                                del_count = int(parts[1]) if parts[1] != '-' else 0
                                filename = parts[2]

                                # ä»çŠ¶æ€æ˜ å°„ä¸­è·å–çœŸå®çš„çŠ¶æ€
                                file_status = status_map.get(filename, 'modified')

                                commit_data['files'].append({
                                    'additions': add_count,
                                    'deletions': del_count,
                                    'filename': filename,
                                    'status': 'added' if file_status == 'A' else 'modified'
                                })
                            except ValueError:
                                continue
        else:
            # è¿œç¨‹ä»“åº“ç”¨ API
            commit_url = f"{GITHUB_API}/repos/{owner}/{repo_name}/commits/{sha}"
            curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{commit_url}"'
            output, returncode = run_command(curl_cmd)
            if returncode == 0:
                try:
                    commit_data = json.loads(output)
                except json.JSONDecodeError:
                    continue

        # ç»Ÿè®¡ additions/deletions å’Œ images
        additions = 0
        deletions = 0
        images = 0

        files_list = commit_data.get('files', [])
        if isinstance(files_list, list):
            for file in files_list:
                file_data: FileData = file
                # ä»£ç è¡Œæ•°ç»Ÿè®¡
                file_additions = file_data.get('additions', 0)
                file_deletions = file_data.get('deletions', 0)
                if isinstance(file_additions, int):
                    additions += file_additions
                if isinstance(file_deletions, int):
                    deletions += file_deletions

                # å›¾ç‰‡ç»Ÿè®¡
                if include_images:
                    file_status = file.get('status', '')
                    if file_status == 'added':
                        filename = file.get('filename', '')
                        if isinstance(filename, str) and is_image_file(filename):
                            images += 1

        total_additions += additions
        total_deletions += deletions
        total_images += images

        # è·å– commit çš„æ—¶é—´æˆ³ï¼ˆç”¨äºç¼“å­˜æ¸…ç†æ—¶çš„æ°¸ä¹…å†å²åˆ¤æ–­ï¼‰
        commit_dict = commit.get('commit', {})
        commit_timestamp: str = ''
        if isinstance(commit_dict, dict):
            author_dict = commit_dict.get('author', {})
            if isinstance(author_dict, dict):
                commit_timestamp = author_dict.get('date', '')
        if not commit_timestamp:
            commit_timestamp = datetime.now().isoformat()

        # æ›´æ–°ç¼“å­˜ï¼ˆæ•°ç»„ç»“æ„ï¼‰
        if repo_name not in cache_data:
            cache_data[repo_name] = []
        cache_data[repo_name].append({
            'index': processed,  # ç¬¬å‡ ä¸ª commit
            'url': commit_url,  # commit é“¾æ¥
            'additions': additions,
            'deletions': deletions,
            'images': images,  # åªä¿å­˜å›¾ç‰‡æ•°é‡
            'timestamp': commit_timestamp  # ä½¿ç”¨ commit çš„æ—¶é—´æˆ³ï¼Œè€Œä¸æ˜¯å½“å‰æ—¶é—´
        })

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print_color("    ğŸ’¾ ç¼“å­˜ç»Ÿè®¡:", Colors.YELLOW)
    print_color(f"       - ç¼“å­˜å‘½ä¸­: {cache_hits} ä¸ªcommit", Colors.NC)
    print_color(f"       - ç¼“å­˜æœªå‘½ä¸­: {cache_misses} ä¸ªcommit", Colors.NC)
    if total_commits > 0:
        cache_hit_rate = (cache_hits / total_commits * 100)
        print_color(f"       - ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%", Colors.NC)

    print_stats_summary(total_additions, total_deletions, total_images, include_images, "    ")

    # ä¿å­˜ç¼“å­˜
    save_cache(repo_name, cache_data)

    return total_additions, total_deletions, total_images


# ============================================================================
# ä»“åº“å¤„ç†
# ============================================================================

def process_repos(repos: List[RepoInfo], include_images: bool = True) -> StatsData:
    """å¤„ç†æ‰€æœ‰ä»“åº“

    Args:
        repos: ä»“åº“åˆ—è¡¨
        include_images: æ˜¯å¦ç»Ÿè®¡å›¾ç‰‡è´¡çŒ®
    """
    print_separator("å¼€å§‹å¤„ç†ä»“åº“...")

    total_additions = 0
    total_deletions = 0
    total_images = 0
    temp_dir = Path.cwd() / "temp_repos"
    temp_dir.mkdir(parents=True, exist_ok=True)

    for repo in repos:
        repo_name = repo.get('name')
        repo_url = repo.get('html_url')
        is_fork = repo.get('fork', False)

        if not repo_name or not repo_url:
            continue

        print_separator(f"ğŸ“¦ ä»“åº“: {repo_name}", Colors.YELLOW)
        print_color("  URL: " + str(repo_url), Colors.NC)
        print_color("  ç±»å‹: " + ('Fork ä»“åº“' if is_fork else 'åŸåˆ›ä»“åº“'), Colors.NC)

        # å…‹éš†ä»“åº“åˆ°ä¸´æ—¶ç›®å½•
        repo_path = temp_dir / str(repo_name)
        if repo_path.exists():
            print_color(f"  ğŸ”„ æ›´æ–°æœ¬åœ°ä»“åº“...", Colors.YELLOW)
            # æ›´æ–°é»˜è®¤åˆ†æ”¯
            run_command("git fetch origin", cwd=str(repo_path))
        else:
            print_color(f"  ğŸ“¥ å…‹éš†ä»“åº“...", Colors.YELLOW)
            clone_url = str(repo_url).replace("https://github.com/", f"https://{TOKEN}@github.com/")
            # å…‹éš†ä»“åº“
            run_command(f"git clone {clone_url}", cwd=str(temp_dir))

        # ç¡®å®šè¦åˆ†æçš„ä»“åº“ï¼ˆfork ä»“åº“ç”¨ä¸Šæ¸¸ä»“åº“ï¼‰
        owner = ORIGIN_USERNAME
        target_repo_name = str(repo_name)

        upstream_owner, upstream_name = get_upstream_repo(repo)
        if upstream_owner and upstream_name:
            owner = upstream_owner
            target_repo_name = str(upstream_name)

        # åŒæ—¶åˆ†æä»£ç è¡Œæ•°å’Œå›¾ç‰‡è´¡çŒ®
        # æ³¨æ„ï¼šrepo_path ç”¨äºè·å– git logï¼Œowner/repo_name ç”¨äº API
        repo_additions, repo_deletions, repo_images = analyze_commits(
            str(repo_path), owner or ORIGIN_USERNAME, target_repo_name, ORIGIN_USERNAME, include_images
        )

        total_images += repo_images

        # æ˜¾ç¤ºç»“æœ
        if repo_additions == 0 and repo_deletions == 0 and repo_images == 0:
            print_color("  âš ï¸  ç”¨æˆ·æ²¡æœ‰ä»£ç æˆ–å›¾ç‰‡è´¡çŒ®", Colors.YELLOW)
        else:
            print_stats_summary(repo_additions, repo_deletions, repo_images, include_images, "  ")

            # ç´¯åŠ åˆ°æ€»è®¡
            total_additions += repo_additions
            total_deletions += repo_deletions

    # æ¸…ç†ä¸´æ—¶ç›®å½•
    print_color("\n  ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...", Colors.YELLOW)
    if temp_dir.exists():
        shutil.rmtree(temp_dir)

    print_separator("ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡")
    print_color(f"  â• æ€» additions: {total_additions}", Colors.GREEN)
    print_color(f"  â– æ€» deletions: {total_deletions}", Colors.GREEN)
    if include_images:
        print_color(f"  ğŸ–¼ï¸ æ€» images: {total_images} images", Colors.GREEN)
    print_separator()

    return {
        'total_additions': total_additions,
        'total_deletions': total_deletions,
        'total_images': total_images
    }


# ============================================================================
# README æ›´æ–°
# ============================================================================

def update_usernames_in_readme(content: str) -> str:
    """æ™ºèƒ½æ›´æ–° README ä¸­çš„ç”¨æˆ·åï¼ˆæ”¯æŒåŒå‘æ›¿æ¢ï¼‰

    ç­–ç•¥ï¼š
    - æ›´æ–° README é¡¶éƒ¨çš„å˜é‡å®šä¹‰ï¼šORIGIN_USERNAME = å’Œ UPSTREAM_USERNAME =
    - æ™ºèƒ½è¯†åˆ«å½“å‰çŠ¶æ€ï¼šå¦‚æœæ˜¯å ä½ç¬¦å°±æ›¿æ¢ä¸ºçœŸå®ç”¨æˆ·åï¼Œå¦‚æœæ˜¯çœŸå®ç”¨æˆ·åå°±ä¿æŒä¸å˜
    - æ”¯æŒå¯é‡å¤è¿è¡Œï¼šæ¯æ¬¡è¿è¡Œéƒ½èƒ½æ­£ç¡®å¤„ç†
    """
    # æ›´æ–°å˜é‡å®šä¹‰
    content = update_variable_definition(content, 'ORIGIN_USERNAME', ORIGIN_USERNAME)
    content = update_variable_definition(content, 'UPSTREAM_USERNAME', UPSTREAM_USERNAME)

    # æ™ºèƒ½æ›¿æ¢å ä½ç¬¦
    placeholder_count = content.count('{{ORIGIN_USERNAME}}') + content.count('{{UPSTREAM_USERNAME}}')

    if placeholder_count > 0:
        # å‘ç°å ä½ç¬¦ï¼Œè¿›è¡Œæ›¿æ¢
        replacements = {
            'ORIGIN_USERNAME': ORIGIN_USERNAME,
            'UPSTREAM_USERNAME': UPSTREAM_USERNAME
        }
        content = replace_placeholders(content, replacements)
        print_color(f"âœ… å·²æ›¿æ¢ {placeholder_count} ä¸ªå ä½ç¬¦ä¸ºçœŸå®ç”¨æˆ·å", Colors.GREEN)
    else:
        # æ²¡æœ‰å ä½ç¬¦ï¼Œè¯´æ˜å·²ç»æ˜¯çœŸå®ç”¨æˆ·åäº†
        print_color(f"â„¹ï¸  æœªå‘ç°å ä½ç¬¦ï¼Œå†…å®¹å·²åŒ…å«çœŸå®ç”¨æˆ·å", Colors.YELLOW)

    return content

def generate_readme_from_template(template_path: Path, stats: StatsData) -> str:
    """ä»æ¨¡æ¿ç”Ÿæˆ README å†…å®¹"""
    with open(template_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # å‡†å¤‡æ›¿æ¢æ•°æ®
    current_time = get_current_time()
    replacements = {
        'ORIGIN_USERNAME': ORIGIN_USERNAME,
        'UPSTREAM_USERNAME': UPSTREAM_USERNAME,
        'TOTAL_ADDITIONS': str(stats.get('total_additions', 0)),
        'TOTAL_DELETIONS': str(stats.get('total_deletions', 0)),
        'TOTAL_IMAGES': str(stats.get('total_images', 0)),
        'LAST_UPDATED': current_time
    }

    # æ›¿æ¢æ‰€æœ‰å ä½ç¬¦
    content = replace_placeholders(content, replacements)
    print_color("âœ… å·²ä»æ¨¡æ¿ç”Ÿæˆå®Œæ•´çš„ README", Colors.GREEN)

    return content

def update_existing_readme(content: str, stats: StatsData) -> str:
    """æ›´æ–°ç°æœ‰ README å†…å®¹"""
    # æ›¿æ¢ç»Ÿè®¡æ•°å­—
    replacement = f'\\g<1>{stats.get("total_additions", 0)}\\g<2>{stats.get("total_deletions", 0)}\\g<3>{stats.get("total_images", 0)}'
    content = re.sub(STATS_PATTERN, replacement, content)

    # æ›¿æ¢æ›´æ–°æ—¶é—´
    current_time = get_current_time()
    time_replacement = f'\\g<1>{current_time}'
    content = re.sub(TIME_PATTERN, time_replacement, content)

    # æ›´æ–°ç”¨æˆ·å
    content = update_usernames_in_readme(content)

    return content

def save_readme_content(content: str) -> bool:
    """ä¿å­˜ README å†…å®¹åˆ°æ–‡ä»¶"""
    try:
        with open(README_FILE_PATH, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print_color(f"âŒ ä¿å­˜ README å¤±è´¥: {e}", Colors.RED)
        return False

def print_update_summary(stats: StatsData) -> None:
    """æ‰“å°æ›´æ–°ç»“æœæ‘˜è¦"""
    current_time = get_current_time()
    print_color("âœ… README.md æ›´æ–°æˆåŠŸï¼", Colors.GREEN)
    print_color(f"   â• å¢åŠ è¡Œæ•°: {stats.get('total_additions', 0)}", Colors.NC)
    print_color(f"   â– åˆ é™¤è¡Œæ•°: {stats.get('total_deletions', 0)}", Colors.NC)
    print_color(f"   ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {stats.get('total_images', 0)}", Colors.NC)
    print_color(f"   ğŸ•’ æ›´æ–°æ—¶é—´: {current_time}", Colors.NC)
    print_color(f"   ğŸ‘¤ å½“å‰ç”¨æˆ·å: {ORIGIN_USERNAME}", Colors.NC)
    print_color(f"   ğŸ‘‘ ä¸Šæ¸¸ç”¨æˆ·å: {UPSTREAM_USERNAME}", Colors.NC)

def update_readme(stats: StatsData) -> bool:
    """æ›´æ–° README.md ä¸­çš„ç»Ÿè®¡æ•°æ®å’Œæ—¶é—´ï¼ˆæ”¯æŒæ¨¡æ¿ç³»ç»Ÿï¼‰

    åŠŸèƒ½ï¼š
    - å¦‚æœå­˜åœ¨ README.template.mdï¼Œä»æ¨¡æ¿ç”Ÿæˆå®Œæ•´çš„ README
    - å¦‚æœä¸å­˜åœ¨æ¨¡æ¿ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›´æ–°ç°æœ‰ README
    - æ”¯æŒå¯é‡å¤è¿è¡Œï¼Œå®Œç¾è§£å†³å ä½ç¬¦æ›¿æ¢é—®é¢˜

    å‚æ•°ï¼š
    - stats: ç»Ÿè®¡æ•°æ®å­—å…¸ï¼ŒåŒ…å« total_additions, total_deletions, total_images
    """
    print_color("ğŸ“ æ›´æ–° README.md...", Colors.YELLOW)

    template_path = Path(__file__).parent.parent / "README.template.md"

    if template_path.exists():
        # ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿ
        print_color("ğŸ“„ ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿç”Ÿæˆ README", Colors.GREEN)
        content = generate_readme_from_template(template_path, stats)
    else:
        # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼æ›´æ–°ç°æœ‰ README
        print_color("âš ï¸  æœªå‘ç°æ¨¡æ¿æ–‡ä»¶ï¼Œæ›´æ–°ç°æœ‰ README", Colors.YELLOW)

        if not README_FILE_PATH.exists():
            print_color("âŒ README.md ä¸å­˜åœ¨ï¼", Colors.RED)
            return False

        # è¯»å–ç°æœ‰ README.md
        with open(README_FILE_PATH, 'r', encoding='utf-8') as f:
            existing_content = f.read()

        content = update_existing_readme(existing_content, stats)

    # ä¿å­˜ README.md
    if not save_readme_content(content):
        return False

    # æ˜¾ç¤ºæ›´æ–°ç»“æœ
    print_update_summary(stats)
    return True


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main() -> int:
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ GitHub ç»Ÿè®¡')
    parser.add_argument('--no-images', action='store_true', help='ä¸ç»Ÿè®¡å›¾ç‰‡è´¡çŒ®')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…é™¤ç¼“å­˜æ–‡ä»¶')
    args = parser.parse_args()

    print_separator("ğŸš€ å¼€å§‹ç”Ÿæˆ GitHub ç»Ÿè®¡...")
    print_color("ğŸ“Š ç»Ÿè®¡é…ç½®:", Colors.YELLOW)
    print_color(f"   - å›¾ç‰‡ç»Ÿè®¡: {'å…³é—­' if args.no_images else 'å¼€å¯'}", Colors.NC)
    if not args.no_images:
        print_color(f"   - ç¼“å­˜ç›®å½•: {CACHE_DIR}", Colors.NC)
    print_separator()

    # å¤„ç†æ¸…é™¤ç¼“å­˜
    if args.clear_cache:
        if CACHE_DIR.exists():
            print_color(f"ğŸ—‘ï¸  æ¸…é™¤ç¼“å­˜ç›®å½•: {CACHE_DIR}", Colors.YELLOW)
            shutil.rmtree(CACHE_DIR)
            print_color("âœ… ç¼“å­˜å·²æ¸…é™¤", Colors.GREEN)
        else:
            print_color("â„¹ï¸  ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: " + str(CACHE_DIR), Colors.NC)
        return 0

    # æ£€æŸ¥ TOKEN
    if not TOKEN:
        print_color("âŒ é”™è¯¯: GH_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®", Colors.RED)
        return 1

    # è·å–ä»“åº“åˆ—è¡¨
    repos = get_repos()
    if not repos:
        print_color("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»“åº“", Colors.YELLOW)
        return 1

    # å¤„ç†ä»“åº“
    stats = process_repos(repos, include_images=not args.no_images)

    # æ›´æ–° README.md
    update_readme(stats)

    print_separator("âœ… è„šæœ¬æ‰§è¡Œå®Œæˆï¼")
    return 0


if __name__ == "__main__":
    exit(main())
