#!/usr/bin/env python3
"""GitHub Contributions Statistics Script

## æ ¸å¿ƒåŠŸèƒ½
- ç»Ÿè®¡æ‰€æœ‰ä»“åº“çš„è´¡çŒ®ï¼ˆadditions/deletionsã€imagesæ•°é‡ï¼‰
- æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿï¼Œé¿å…é‡å¤åˆ†æå·²å¤„ç†çš„ commits
- æ”¯æŒ Fork ä»“åº“ï¼ˆè‡ªåŠ¨åˆ†æä¸Šæ¸¸ä»“åº“ï¼‰
- è‡ªåŠ¨æ›´æ–° README.md ç»Ÿè®¡æ•°æ®å’Œæ—¶é—´

## æ•°æ®æº
- æœ¬åœ° git logï¼šå®Œæ•´å†å²æ•°æ®
- GitHub APIï¼šæœ€æ–°æ•°æ®ï¼ˆæœ€å¤š 1000 ä¸ª commitsï¼‰
- æ™ºèƒ½åˆå¹¶ï¼šå–ä¸¤è€…ä¼˜åŠ¿ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§

## ç¼“å­˜æœºåˆ¶
æ¯ä¸ªä»“åº“ä¸€ä¸ª JSON æ–‡ä»¶ï¼ŒåŒ…å«ï¼š
- å…ƒæ•°æ®ï¼šæ€» commits æ•°ã€æ€» additions/deletions æ•°ã€æ€» images æ•°
- è¯¦ç»†æ•°æ®ï¼šæ¯ä¸ª commit çš„ç»Ÿè®¡æ•°æ®

## æ›´æ–°ç­–ç•¥
- åªæœ‰è¿è¡Œè„šæœ¬æ—¶æ‰æ›´æ–°æ•°æ®
- ä½¿ç”¨æ­£åˆ™åŒ¹é…æ›¿æ¢ï¼Œä¿æŒ README.md åŸæœ‰æ ¼å¼
- æ°¸ä¹…ä¿å­˜å†å²æ•°æ®ï¼Œæ™ºèƒ½æ¸…ç†è¿‡æœŸç¼“å­˜
"""

import os
import subprocess
import json
import re
import shutil
import argparse
from pathlib import Path
from datetime import datetime, timezone, timedelta

# ============================================================================
# é…ç½®
# ============================================================================

GITHUB_API = "https://api.github.com"
USERNAME = os.environ.get("USERNAME", "Usagi-wusaqi")
TOKEN = os.environ.get("GH_TOKEN")
CACHE_DIR = Path(__file__).parent / "stats_cache"


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

class Colors:
    """ç»ˆç«¯é¢œè‰²å®šä¹‰"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    NC = '\033[0m'


def print_color(message, color=Colors.NC):
    """å½©è‰²è¾“å‡º"""
    print(f"{color}{message}{Colors.NC}")


def run_command(cmd, cwd=None):
    """è¿è¡Œå‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            cwd=cwd
        )
        return result.stdout.strip(), result.returncode
    except Exception as e:
        print_color(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}", Colors.RED)
        return "", 1


# ============================================================================
# ç¼“å­˜ç®¡ç†
# ============================================================================

def load_cache(repo_name):
    """åŠ è½½æŒ‡å®šä»“åº“çš„ç¼“å­˜æ•°æ®"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_file = CACHE_DIR / f"{repo_name}.json"

    try:
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
            print_color(f"ğŸ’¾ å·²åŠ è½½ç¼“å­˜: {cache_file}", Colors.GREEN)

            # å¤„ç†æ–°æ—§ç¼“å­˜æ ¼å¼
            if '_metadata' in cache_data:
                metadata = cache_data['_metadata']
                print_color(f"   ç¼“å­˜åŒ…å« {metadata.get('total_commits', 0)} ä¸ªcommits", Colors.NC)
                return cache_data.get('data', {})
            else:
                # æ—§æ ¼å¼ï¼Œç›´æ¥è¿”å›
                print_color(f"   ç¼“å­˜åŒ…å« {len(cache_data)} ä¸ªcommitsçš„æ•°æ®", Colors.NC)
                return cache_data
    except (json.JSONDecodeError, IOError) as e:
        print_color(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}", Colors.YELLOW)
        return {}


def save_cache(repo_name, cache_data):
    """ä¿å­˜æŒ‡å®šä»“åº“çš„ç¼“å­˜æ•°æ®

    åŠŸèƒ½ï¼š
    - æŒ‰æ—¶é—´æˆ³æ’åº commitsï¼ˆä»æ—§åˆ°æ–°ï¼‰
    - é‡æ–°ç¼–å· commit indexï¼ˆä» 1 å¼€å§‹ï¼‰
    - ç»Ÿè®¡æ€» commits æ•°ã€æ€»å¢åˆ è¡Œæ•°å’Œæ€»å›¾ç‰‡æ•°
    - ä¿å­˜ä¸ºå¸¦ metadata çš„ JSON æ ¼å¼

    å‚æ•°ï¼š
    - repo_name: ä»“åº“åç§°
    - cache_data: ç¼“å­˜æ•°æ®å­—å…¸

    JSON è¾“å‡ºæ ¼å¼ï¼š
    {
      "_metadata": {
        "total_commits": int,    // æ€» commit æ•°
        "total_additions": int,  // æ€»å¢åŠ è¡Œæ•°
        "total_deletions": int,  // æ€»åˆ é™¤è¡Œæ•°
        "total_images": int      // æ€»å›¾ç‰‡æ•°
      },
      "data": { ... }            // commit æ•°æ®
    }
    """
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    cache_file = CACHE_DIR / f"{repo_name}.json"

    try:
        # å¯¹æ¯ä¸ªä»“åº“çš„ commits æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
        sorted_cache_data = {}
        total_commits = 0
        total_images = 0
        total_additions = 0
        total_deletions = 0

        for repo_name, commits in cache_data.items():
            if isinstance(commits, list):
                # æŒ‰ timestamp ä»æ—§åˆ°æ–°æ’åºï¼ˆè€çš„åœ¨å‰ï¼Œæ–°çš„åœ¨åï¼‰
                sorted_commits = sorted(commits, key=lambda x: x.get('timestamp', ''))

                # é‡æ–°ç¼–å· indexï¼ˆä» 1 å¼€å§‹ï¼‰å¹¶ç»Ÿè®¡å„é¡¹æ•°æ®
                repo_images = 0
                repo_additions = 0
                repo_deletions = 0
                for idx, commit in enumerate(sorted_commits, start=1):
                    commit['index'] = idx
                    repo_additions += commit.get('additions', 0)
                    repo_deletions += commit.get('deletions', 0)
                    repo_images += commit.get('images', 0)

                sorted_cache_data[repo_name] = sorted_commits
                total_commits += len(sorted_commits)
                total_additions += repo_additions
                total_deletions += repo_deletions
                total_images += repo_images
            else:
                # æ—§æ ¼å¼ï¼Œä¿æŒåŸæ ·
                sorted_cache_data[repo_name] = commits
                total_commits += len(commits)
                # æ—§æ ¼å¼ä¹Ÿå°è¯•ç»Ÿè®¡å„é¡¹æ•°æ®
                if isinstance(commits, dict):
                    for commit_data in commits.values():
                        total_additions += commit_data.get('additions', 0)
                        total_deletions += commit_data.get('deletions', 0)
                        total_images += commit_data.get('images', 0)

        cache_data_with_metadata = {
            '_metadata': {
                'total_commits': total_commits,
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'total_images': total_images
            },
            'data': sorted_cache_data
        }

        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data_with_metadata, f, indent=2, ensure_ascii=False)

        print_color(f"âœ… ç¼“å­˜å·²ä¿å­˜: {cache_file}", Colors.GREEN)
        print_color(f"   commits: {cache_data_with_metadata['_metadata']['total_commits']}", Colors.NC)
        print_color(f"   additions: {cache_data_with_metadata['_metadata']['total_additions']}", Colors.NC)
        print_color(f"   deletions: {cache_data_with_metadata['_metadata']['total_deletions']}", Colors.NC)
        print_color(f"   images: {cache_data_with_metadata['_metadata']['total_images']}", Colors.NC)
        return True
    except Exception as e:
        print_color(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}", Colors.YELLOW)
        return False


def clean_stale_cache(cache_data, current_commits_with_data, repo_key):
    """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜ï¼ˆæ£€æµ‹å˜åŸºç­‰å¯¼è‡´çš„commitå“ˆå¸Œå˜åŒ–ï¼‰

    ç­–ç•¥ï¼š
    1. åªæ¸…é™¤åœ¨å½“å‰åˆå¹¶æ•°æ®ä¸­æ¶ˆå¤±çš„ commitsï¼ˆå¯èƒ½è¢«å˜åŸºã€å‹ç¼©æˆ–é‡å†™ï¼‰
    2. æ°¸ä¹…ä¿å­˜æ¯”å½“å‰æœ€è€ commit è¿˜è¦ä¹…è¿œçš„ç¼“å­˜æ•°æ®ï¼ˆæŸ¥ä¸åˆ°çš„å†å²ï¼‰
    3. æ›´æ–°æ–°çš„ commits åˆ°ç¼“å­˜

    å‚æ•°ï¼š
    - current_commits_with_data: å½“å‰åˆå¹¶åçš„å®Œæ•´ commit å¯¹è±¡åˆ—è¡¨ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    """
    if repo_key not in cache_data:
        return cache_data

    # è·å–å½“å‰æ•°æ®çš„ sha é›†åˆå’Œæœ€è€çš„æ—¶é—´æˆ³
    current_commit_set = set()
    oldest_current_time = None

    for commit in current_commits_with_data:
        sha = commit.get('sha')
        if sha:
            current_commit_set.add(sha)

        # è·å– commit æ—¶é—´æˆ³
        commit_time = commit.get('commit', {}).get('author', {}).get('date', '')
        if commit_time:
            if oldest_current_time is None or commit_time < oldest_current_time:
                oldest_current_time = commit_time

    # æ–°æ ¼å¼ï¼šæ•°ç»„ç»“æ„
    if isinstance(cache_data[repo_key], list):
        # ä» URL ä¸­æå– sha
        cached_shas = set()
        for item in cache_data[repo_key]:
            url = item.get('url', '')
            if url:
                sha = url.split('/')[-1]  # ä» URL æœ«å°¾æå– sha
                cached_shas.add(sha)
    else:
        # æ—§æ ¼å¼ï¼šå¯¹è±¡ç»“æ„
        cached_shas = set(cache_data[repo_key].keys())

    # æ‰¾å‡ºåœ¨å½“å‰åˆå¹¶æ•°æ®ä¸­æ¶ˆå¤±çš„ commits
    stale_commits = cached_shas - current_commit_set

    if stale_commits:
        print_color(f"    ğŸ§¹ æ£€æµ‹åˆ° {len(stale_commits)} ä¸ªæ¶ˆå¤±çš„commits", Colors.YELLOW)
        print_color(f"       åŸå› ï¼šå¯èƒ½è¢«å˜åŸºã€å‹ç¼©æˆ–é‡å†™", Colors.YELLOW)

        deleted_count = 0
        preserved_count = 0

        if isinstance(cache_data[repo_key], list):
            # æ–°æ ¼å¼ï¼šè¿‡æ»¤æ•°ç»„
            new_cache_list = []
            for item in cache_data[repo_key]:
                url = item.get('url', '')
                sha = url.split('/')[-1] if url else ''
                cached_commit_time = item.get('timestamp', '')

                # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ é™¤
                if sha in stale_commits:
                    if oldest_current_time and cached_commit_time < oldest_current_time:
                        # ä¿ç•™æ°¸ä¹…å†å²æ•°æ®
                        new_cache_list.append(item)
                        preserved_count += 1
                    else:
                        # åˆ é™¤åœ¨å½“å‰æ•°æ®èŒƒå›´å†…æ¶ˆå¤±çš„ commits
                        deleted_count += 1
                else:
                    new_cache_list.append(item)

            cache_data[repo_key] = new_cache_list
        else:
            # æ—§æ ¼å¼ï¼šåˆ é™¤å­—å…¸é”®
            repo_cache = cache_data[repo_key]
            for commit_sha in list(stale_commits):
                cached_commit_time = repo_cache[commit_sha].get('timestamp', '')

                if oldest_current_time and cached_commit_time < oldest_current_time:
                    preserved_count += 1
                else:
                    del repo_cache[commit_sha]
                    deleted_count += 1

        print_color(f"    âœ… å·²æ¸…é™¤ {deleted_count} ä¸ªè¿‡æœŸçš„commitç¼“å­˜åŠå…¶ç»Ÿè®¡æ•°æ®", Colors.GREEN)
        if preserved_count > 0:
            print_color(f"    â„¹ï¸  ä¿ç•™ {preserved_count} ä¸ªæ°¸ä¹…å†å²æ•°æ®ï¼ˆæ¯”å½“å‰æœ€è€æ•°æ®æ›´ä¹…è¿œï¼‰", Colors.NC)

        # å¦‚æœä»“åº“ç¼“å­˜ä¸ºç©ºï¼Œåˆ é™¤è¯¥ä»“åº“çš„ç¼“å­˜æ¡ç›®
        if not repo_cache:
            del cache_data[repo_key]
            print_color(f"    â„¹ï¸  ä»“åº“ç¼“å­˜å·²æ¸…ç©º", Colors.NC)
    else:
        print_color(f"    âœ… ç¼“å­˜æ•°æ®å®Œæ•´ï¼Œæ— æ¶ˆå¤±çš„commits", Colors.GREEN)

    return cache_data


# ============================================================================
# GitHub API æ“ä½œ
# ============================================================================

def get_repos():
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰ä»“åº“ï¼ˆåŒ…æ‹¬å…¬å¼€å’Œç§æœ‰ä»“åº“ï¼‰"""
    print_color("ğŸ“¡ è·å–æ‰€æœ‰ä»“åº“åˆ—è¡¨...", Colors.YELLOW)

    # ä½¿ç”¨ curl è·å–ä»“åº“åˆ—è¡¨
    curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{GITHUB_API}/users/{USERNAME}/repos?per_page=100&type=all"'
    output, returncode = run_command(curl_cmd)

    if returncode != 0:
        print_color("âŒ è·å–ä»“åº“åˆ—è¡¨å¤±è´¥", Colors.RED)
        return []

    # è§£æ JSON
    try:
        repos = json.loads(output)
        if not isinstance(repos, list):
            print_color(f"âŒ API è¿”å›çš„æ•°æ®æ ¼å¼é”™è¯¯: {type(repos)}", Colors.RED)
            print_color(f"æ•°æ®å†…å®¹: {output[:500]}", Colors.RED)
            return []

        print_color(f"âœ… è·å–åˆ° {len(repos)} ä¸ªä»“åº“", Colors.GREEN)
        for repo in repos:
            repo_name = repo.get('name', 'Unknown')
            is_fork = repo.get('fork', False)
            print_color(f"   - {repo_name} ({'Fork' if is_fork else 'åŸåˆ›'})", Colors.NC)
        return repos
    except json.JSONDecodeError as e:
        print_color(f"âŒ JSON è§£æå¤±è´¥: {e}", Colors.RED)
        print_color(f"æ•°æ®å†…å®¹: {output[:500]}", Colors.RED)
        return []


def get_upstream_repo(repo):
    """è·å– fork ä»“åº“çš„ä¸Šæ¸¸ä»“åº“ä¿¡æ¯"""
    if not repo.get('fork'):
        return None, None

    upstream_info = repo.get('source') or repo.get('parent') or {}
    if upstream_info:
        upstream_owner = upstream_info.get('owner', {}).get('login')
        upstream_name = upstream_info.get('name')
        if upstream_owner and upstream_name:
            return upstream_owner, upstream_name
    return None, None


# ============================================================================
# Commits æ•°æ®è·å–
# ============================================================================

def get_commits_from_git_log(repo_path, username, default_branch):
    """ä»æœ¬åœ° git log è·å–ç”¨æˆ·çš„æ‰€æœ‰ commitsï¼ˆå®Œæ•´å†å²ï¼‰"""
    git_cmd = f'git log origin/{default_branch} --author="{username}" --format="%H"'
    output, returncode = run_command(git_cmd, cwd=repo_path)

    if returncode == 0:
        commit_hashes = [h.strip() for h in output.split('\n') if h.strip()]
        all_commits = [{'sha': h} for h in commit_hashes]
        print_color(f"    â„¹ï¸  git log è·å– {len(all_commits)} ä¸ªcommits", Colors.NC)
        return all_commits
    else:
        print_color(f"    âš ï¸  git log å¤±è´¥", Colors.YELLOW)
        return None


def get_commits_from_api(owner, repo_name, username, max_pages=10):
    """ä» GitHub API è·å–ç”¨æˆ·çš„æœ€è¿‘ commitsï¼ˆåˆ†é¡µï¼Œæœ€å¤š 10 é¡µï¼‰

    åªè·å–æœ€è¿‘çš„ commitsï¼Œå¾ˆä¹…ä»¥å‰çš„ commits ä»ç¼“å­˜è¯»å–
    """
    page = 1
    per_page = 100
    all_commits = []

    while page <= max_pages:
        api_url = f"{GITHUB_API}/repos/{owner}/{repo_name}/commits?author={username}&per_page={per_page}&page={page}"
        print_color(f"    ğŸ” è·å–commits (ç¬¬{page}é¡µ)...", Colors.NC)

        curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{api_url}"'
        output, returncode = run_command(curl_cmd)

        if returncode != 0:
            print_color("    âŒ APIè°ƒç”¨å¤±è´¥", Colors.RED)
            return all_commits if all_commits else []

        try:
            commits = json.loads(output)
            if not isinstance(commits, list):
                print_color("    âŒ APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯", Colors.RED)
                return all_commits if all_commits else []

            if not commits:
                break

            all_commits.extend(commits)
            print_color(f"    ğŸ“Š å·²è·å– {len(all_commits)} ä¸ªcommits", Colors.NC)

            if len(commits) < per_page:
                break

            page += 1

        except json.JSONDecodeError as e:
            print_color(f"    âŒ JSON è§£æå¤±è´¥: {e}", Colors.RED)
            return all_commits if all_commits else []

    if page > max_pages:
        print_color(f"    â„¹ï¸  å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({max_pages} é¡µ)ï¼Œå…± {len(all_commits)} ä¸ªcommits", Colors.NC)
        print_color(f"    â„¹ï¸  æ›´ä¹…ä»¥å‰çš„ commits å°†ä»ç¼“å­˜è¯»å–", Colors.NC)

    return all_commits


def merge_commits(git_commits, api_commits):
    """åˆå¹¶ git log å’Œ API çš„ commits æ•°æ®

    ç­–ç•¥ï¼ˆæ•°æ®ç›¸äº¤ï¼‰ï¼š
    1. åŒæ—¶ä½¿ç”¨ git logï¼ˆå®Œæ•´å†å²ï¼‰å’Œ APIï¼ˆæœ€è¿‘ 10 é¡µï¼‰çš„æ•°æ®
    2. å¯¹äºç›¸åŒçš„ commitsï¼šæ¯”è¾ƒæ—¶é—´æˆ³ï¼Œè°çš„æ•°æ®æ›´æ–°å°±ç”¨è°çš„
    3. å¯¹äºä¸åŒçš„ commitsï¼šä¿ç•™å„è‡ªçš„æ•°æ®
    4. ç»“æœï¼šgit log çš„è€æ•°æ® + API çš„æ–°æ•°æ® + æœ€æ–°çš„æ›´æ–°

    è¿™æ ·å¯ä»¥å¤„ç†ï¼š
    - git log æ²¡æ›´æ–°çš„æƒ…å†µï¼ˆç”¨ API çš„æ–°æ•°æ®ï¼‰
    - API é™æµæˆ–æ²¡æ›´æ–°çš„æƒ…å†µï¼ˆç”¨ git log çš„æ•°æ®ï¼‰
    - ä¸¤ä¸ªæ•°æ®æºéƒ½æœ‰å„è‡ªç‹¬ç‰¹çš„æ•°æ®ï¼ˆéƒ½ä¿ç•™ï¼‰
    """
    git_count = len(git_commits) if git_commits else 0
    api_count = len(api_commits) if api_commits else 0

    print_color(f"    ğŸ“Š åˆå¹¶æ•°æ®æº:", Colors.YELLOW)
    print_color(f"       - git log: {git_count} ä¸ªcommitsï¼ˆå®Œæ•´å†å²ï¼‰", Colors.NC)
    print_color(f"       - API: {api_count} ä¸ªcommitsï¼ˆæœ€å¤š 10 é¡µï¼‰", Colors.NC)

    if not git_commits and not api_commits:
        print_color(f"    âŒ ä¸¤ä¸ªæ•°æ®æºéƒ½æ— æ•°æ®", Colors.RED)
        return []

    if not git_commits:
        print_color(f"    âœ… ä»…ä½¿ç”¨ API æ•°æ®", Colors.GREEN)
        return api_commits

    if not api_commits:
        print_color(f"    âœ… ä»…ä½¿ç”¨ git log æ•°æ®", Colors.GREEN)
        return git_commits

    # æ„å»º commit æ˜ å°„ï¼ˆsha -> commit å¯¹è±¡ï¼‰
    git_map = {c.get('sha'): c for c in git_commits if c.get('sha')}
    api_map = {c.get('sha'): c for c in api_commits if c.get('sha')}

    # æ‰¾å‡ºç›¸åŒå’Œä¸åŒçš„ commits
    git_shas = set(git_map.keys())
    api_shas = set(api_map.keys())
    common_shas = git_shas & api_shas
    git_only_shas = git_shas - api_shas
    api_only_shas = api_shas - git_shas

    print_color(f"    ğŸ“Š æ•°æ®åˆ†æ:", Colors.YELLOW)
    print_color(f"       - ç›¸åŒ commits: {len(common_shas)}", Colors.NC)
    print_color(f"       - ä»…åœ¨ git log: {len(git_only_shas)}", Colors.NC)
    print_color(f"       - ä»…åœ¨ API: {len(api_only_shas)}", Colors.NC)

    # åˆå¹¶ç»“æœ
    merged = {}

    # 1. å¤„ç†ç›¸åŒçš„ commitsï¼šæ¯”è¾ƒæ—¶é—´æˆ³ï¼Œè°çš„æ–°ç”¨è°çš„
    for sha in common_shas:
        git_commit = git_map[sha]
        api_commit = api_map[sha]

        git_time = git_commit.get('commit', {}).get('author', {}).get('date', '')
        api_time = api_commit.get('commit', {}).get('author', {}).get('date', '')

        # æ¯”è¾ƒæ—¶é—´æˆ³ï¼ˆISO æ ¼å¼å¯ä»¥ç›´æ¥å­—ç¬¦ä¸²æ¯”è¾ƒï¼‰
        if api_time > git_time:
            # API æ•°æ®æ›´æ–°
            merged[sha] = api_commit
        else:
            # git log æ•°æ®æ›´æ–°æˆ–ç›¸åŒ
            merged[sha] = git_commit

    # 2. ä¿ç•™ git log ç‹¬æœ‰çš„ commitsï¼ˆè€æ•°æ®ï¼‰
    for sha in git_only_shas:
        merged[sha] = git_map[sha]

    # 3. ä¿ç•™ API ç‹¬æœ‰çš„ commitsï¼ˆæ–°æ•°æ®ï¼‰
    for sha in api_only_shas:
        merged[sha] = api_map[sha]

    result = list(merged.values())
    print_color(f"    âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(result)} ä¸ªcommits", Colors.GREEN)
    return result


# ============================================================================
# Commits åˆ†æ
# ============================================================================

def analyze_commits(repo_path, owner, repo_name, username, include_images=True):
    """åŒæ—¶åˆ†æä»£ç è¡Œæ•°å’Œå›¾ç‰‡è´¡çŒ®

    è¿”å›: (additions, deletions, total_images)
    """
    print_color(f"    ğŸ“Š å¼€å§‹åˆ†æcommits...", Colors.YELLOW)

    # åŠ è½½ç¼“å­˜
    cache_data = load_cache(repo_name)

    # è·å– commitsï¼ˆåŒæ—¶å°è¯• git log å’Œ APIï¼Œé€‰æ‹©æœ€æ–°çš„ï¼‰
    git_commits = None
    api_commits = None
    default_branch = 'main'

    # 1. å°è¯•ä»æœ¬åœ° git log è·å–
    if repo_path:
        git_cmd = 'git symbolic-ref refs/remotes/origin/HEAD | sed "s@^refs/remotes/origin/@@"'
        output, returncode = run_command(git_cmd, cwd=repo_path)
        default_branch = output.strip() if returncode == 0 else 'main'

        print_color(f"    â„¹ï¸  é»˜è®¤åˆ†æ”¯: {default_branch}", Colors.NC)
        git_commits = get_commits_from_git_log(repo_path, username, default_branch)

    # 2. å°è¯•ä» API è·å–
    api_commits = get_commits_from_api(owner, repo_name, username)

    # 3. åˆå¹¶ä¸¤ä¸ªæ•°æ®æºï¼ˆæ•°æ®ç›¸äº¤ç­–ç•¥ï¼‰
    all_commits = merge_commits(git_commits, api_commits)

    if not all_commits:
        print_color(f"    â„¹ï¸  æœªæ‰¾åˆ°commits", Colors.NC)
        return 0, 0, 0

    total_commits = len(all_commits)
    print_color(f"    ğŸ“Š æœ€ç»ˆä½¿ç”¨ {total_commits} ä¸ªcommits", Colors.NC)

    # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆä¼ å…¥å®Œæ•´çš„ commit å¯¹è±¡ä»¥è·å–æ—¶é—´æˆ³ï¼‰
    cache_data = clean_stale_cache(cache_data, all_commits, repo_name)

    # ç»Ÿè®¡æ•°æ®
    total_additions = 0
    total_deletions = 0
    total_images = 0
    processed = 0
    cache_hits = 0
    cache_misses = 0

    for commit in all_commits:
        sha = commit.get('sha')
        if not sha:
            continue

        processed += 1
        if processed % 10 == 0:
            print_color(f"    ğŸ“Š å¤„ç†ä¸­: {processed}/{total_commits} ({processed*100//total_commits}%)", Colors.NC)

        # æ£€æŸ¥ç¼“å­˜
        commit_url = f"https://github.com/{owner}/{repo_name}/commit/{sha}"
        cached_data = None
        if repo_name in cache_data and isinstance(cache_data[repo_name], list):
            # æ–°æ ¼å¼ï¼šæ•°ç»„ç»“æ„
            for item in cache_data[repo_name]:
                if item.get('url') == commit_url:
                    cached_data = item
                    break

        if cached_data:
            total_additions += cached_data.get('additions', 0)
            total_deletions += cached_data.get('deletions', 0)
            if include_images:
                total_images += cached_data.get('images', 0)
            cache_hits += 1
            continue

        cache_misses += 1
        commit_data = {}

        # è·å– commit è¯¦æƒ…
        if repo_path:
            # æœ¬åœ°ä»“åº“ç”¨ git show
            # å…ˆè·å–æ–‡ä»¶çŠ¶æ€ï¼ˆA=added, M=modified, D=deleted ç­‰ï¼‰
            git_cmd = f'git show --name-status --pretty="" {sha}'
            status_output, returncode = run_command(git_cmd, cwd=repo_path)

            # å†è·å–æ–‡ä»¶çš„è¡Œæ•°ç»Ÿè®¡
            git_cmd = f'git show --numstat --pretty="" {sha}'
            numstat_output, returncode = run_command(git_cmd, cwd=repo_path)

            if returncode == 0:
                commit_data['files'] = []

                # æ„å»ºçŠ¶æ€æ˜ å°„
                status_map = {}
                for line in status_output.split('\n'):
                    if line.strip():
                        parts = line.split('\t')
                        if len(parts) >= 2:
                            status = parts[0]  # A, M, D ç­‰
                            filename = parts[1]
                            status_map[filename] = status

                # å¤„ç†è¡Œæ•°ç»Ÿè®¡
                for line in numstat_output.split('\n'):
                    if line.strip():
                        parts = line.split('\t')
                        if len(parts) >= 3:
                            try:
                                add_count = int(parts[0]) if parts[0] != '-' else 0
                                del_count = int(parts[1]) if parts[1] != '-' else 0
                                filename = parts[2]

                                # ä»çŠ¶æ€æ˜ å°„ä¸­è·å–çœŸå®çš„çŠ¶æ€
                                file_status = status_map.get(filename, 'modified')

                                commit_data['files'].append({
                                    'additions': add_count,
                                    'deletions': del_count,
                                    'filename': filename,
                                    'status': 'added' if file_status == 'A' else 'modified'
                                })
                            except ValueError:
                                continue
        else:
            # è¿œç¨‹ä»“åº“ç”¨ API
            commit_url = f"{GITHUB_API}/repos/{owner}/{repo_name}/commits/{sha}"
            curl_cmd = f'curl -s -H "Authorization: token {TOKEN}" -H "Accept: application/vnd.github.v3+json" "{commit_url}"'
            output, returncode = run_command(curl_cmd)
            if returncode == 0:
                try:
                    commit_data = json.loads(output)
                except json.JSONDecodeError:
                    continue

        # ç»Ÿè®¡ additions/deletions å’Œ images
        additions = 0
        deletions = 0
        images = 0

        for file in commit_data.get('files', []):
            # ä»£ç è¡Œæ•°ç»Ÿè®¡
            if 'additions' in file and 'deletions' in file:
                additions += file.get('additions', 0)
                deletions += file.get('deletions', 0)

            # å›¾ç‰‡ç»Ÿè®¡
            if include_images and file.get('status') == 'added':
                filename = file.get('filename', '')
                if any(filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.webp', '.ico']):
                    images += 1

        total_additions += additions
        total_deletions += deletions
        total_images += images

        # è·å– commit çš„æ—¶é—´æˆ³ï¼ˆç”¨äºç¼“å­˜æ¸…ç†æ—¶çš„æ°¸ä¹…å†å²åˆ¤æ–­ï¼‰
        commit_timestamp = commit.get('commit', {}).get('author', {}).get('date', '')
        if not commit_timestamp:
            commit_timestamp = datetime.now().isoformat()

        # æ›´æ–°ç¼“å­˜ï¼ˆæ•°ç»„ç»“æ„ï¼‰
        if repo_name not in cache_data:
            cache_data[repo_name] = []
        cache_data[repo_name].append({
            'index': processed,  # ç¬¬å‡ ä¸ª commit
            'url': commit_url,  # commit é“¾æ¥
            'additions': additions,
            'deletions': deletions,
            'images': images,  # åªä¿å­˜å›¾ç‰‡æ•°é‡
            'timestamp': commit_timestamp  # ä½¿ç”¨ commit çš„æ—¶é—´æˆ³ï¼Œè€Œä¸æ˜¯å½“å‰æ—¶é—´
        })

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print_color("    ğŸ’¾ ç¼“å­˜ç»Ÿè®¡:", Colors.YELLOW)
    print_color(f"       - ç¼“å­˜å‘½ä¸­: {cache_hits} ä¸ªcommit", Colors.NC)
    print_color(f"       - ç¼“å­˜æœªå‘½ä¸­: {cache_misses} ä¸ªcommit", Colors.NC)
    if total_commits > 0:
        cache_hit_rate = (cache_hits / total_commits * 100)
        print_color(f"       - ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%", Colors.NC)

    print_color(f"    âœ… ä»£ç è´¡çŒ®: +{total_additions} additions, -{total_deletions} deletions", Colors.GREEN)
    if include_images:
        print_color(f"    âœ… å›¾ç‰‡è´¡çŒ®: {total_images} images", Colors.GREEN)

    # ä¿å­˜ç¼“å­˜
    save_cache(repo_name, cache_data)

    return total_additions, total_deletions, total_images


# ============================================================================
# ä»“åº“å¤„ç†
# ============================================================================

def process_repos(repos, include_images=True):
    """å¤„ç†æ‰€æœ‰ä»“åº“

    Args:
        repos: ä»“åº“åˆ—è¡¨
        include_images: æ˜¯å¦ç»Ÿè®¡å›¾ç‰‡è´¡çŒ®
    """
    print_color("=" * 60, Colors.GREEN)
    print_color("å¼€å§‹å¤„ç†ä»“åº“...", Colors.GREEN)
    print_color("=" * 60, Colors.GREEN)

    total_additions = 0
    total_deletions = 0
    total_images = 0
    temp_dir = Path.cwd() / "temp_repos"
    temp_dir.mkdir(parents=True, exist_ok=True)

    for repo in repos:
        repo_name = repo.get('name')
        repo_url = repo.get('html_url')
        is_fork = repo.get('fork', False)

        if not repo_name or not repo_url:
            continue

        print_color("\n" + "=" * 60, Colors.GREEN)
        print_color(f"ğŸ“¦ ä»“åº“: {repo_name}", Colors.YELLOW)
        print_color("=" * 60, Colors.GREEN)
        print_color("  URL: " + repo_url, Colors.NC)
        print_color("  ç±»å‹: " + ('Fork ä»“åº“' if is_fork else 'åŸåˆ›ä»“åº“'), Colors.NC)

        # å…‹éš†ä»“åº“åˆ°ä¸´æ—¶ç›®å½•
        repo_path = temp_dir / repo_name
        if repo_path.exists():
            print_color(f"  ğŸ”„ æ›´æ–°æœ¬åœ°ä»“åº“...", Colors.YELLOW)
            # æ›´æ–°é»˜è®¤åˆ†æ”¯
            run_command("git fetch origin", cwd=str(repo_path))
        else:
            print_color(f"  ğŸ“¥ å…‹éš†ä»“åº“...", Colors.YELLOW)
            clone_url = repo_url.replace("https://github.com/", f"https://{TOKEN}@github.com/")
            # å…‹éš†ä»“åº“
            run_command(f"git clone {clone_url}", cwd=str(temp_dir))

        # ç¡®å®šè¦åˆ†æçš„ä»“åº“ï¼ˆfork ä»“åº“ç”¨ä¸Šæ¸¸ä»“åº“ï¼‰
        owner = USERNAME
        target_repo_name = repo_name

        upstream_owner, upstream_name = get_upstream_repo(repo)
        if upstream_owner and upstream_name:
            owner = upstream_owner
            target_repo_name = upstream_name

        # åŒæ—¶åˆ†æä»£ç è¡Œæ•°å’Œå›¾ç‰‡è´¡çŒ®
        # æ³¨æ„ï¼šrepo_path ç”¨äºè·å– git logï¼Œowner/repo_name ç”¨äº API
        repo_additions, repo_deletions, repo_images = analyze_commits(
            str(repo_path), owner, target_repo_name, USERNAME, include_images
        )

        total_images += repo_images

        # æ˜¾ç¤ºç»“æœ
        if repo_additions == 0 and repo_deletions == 0 and repo_images == 0:
            print_color("  âš ï¸  ç”¨æˆ·æ²¡æœ‰ä»£ç æˆ–å›¾ç‰‡è´¡çŒ®", Colors.YELLOW)
        else:
            print_color(f"  âœ… ä»£ç è´¡çŒ®: +{repo_additions} additions, -{repo_deletions} deletions", Colors.GREEN)
            if include_images:
                print_color(f"  âœ… å›¾ç‰‡è´¡çŒ®: {repo_images} images", Colors.GREEN)

            # ç´¯åŠ åˆ°æ€»è®¡
            total_additions += repo_additions
            total_deletions += repo_deletions

    # æ¸…ç†ä¸´æ—¶ç›®å½•
    print_color("\n  ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...", Colors.YELLOW)
    if temp_dir.exists():
        shutil.rmtree(temp_dir)

    print_color("\n" + "=" * 60, Colors.GREEN)
    print_color("ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡", Colors.GREEN)
    print_color("=" * 60, Colors.GREEN)
    print_color(f"  â• æ€» additions: {total_additions}", Colors.GREEN)
    print_color(f"  â– æ€» deletions: {total_deletions}", Colors.GREEN)
    if include_images:
        print_color(f"  ğŸ–¼ï¸ æ€» images: {total_images} images", Colors.GREEN)
    print_color("=" * 60, Colors.GREEN)

    return {
        'total_additions': total_additions,
        'total_deletions': total_deletions,
        'total_images': total_images
    }


# ============================================================================
# README æ›´æ–°
# ============================================================================

def update_readme(stats):
    """æ›´æ–° README.md ä¸­çš„ç»Ÿè®¡æ•°æ®å’Œæ—¶é—´

    åŠŸèƒ½ï¼š
    - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ›¿æ¢ç»Ÿè®¡æ•°å­—
    - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ›¿æ¢æ›´æ–°æ—¶é—´
    - ä¿æŒåŸæœ‰ HTML æ ¼å¼å’Œæ ·å¼ä¸å˜

    æ›¿æ¢å†…å®¹ï¼š
    1. â•additions: æ•°å­— â–deletions: æ•°å­— ğŸ–¼ï¸images: æ•°å­—
    2. æœ€åæ›´æ–°: YYYY-MM-DD HH:MM:SS

    å‚æ•°ï¼š
    - stats: ç»Ÿè®¡æ•°æ®å­—å…¸ï¼ŒåŒ…å« total_additions, total_deletions, total_images
    """
    print_color("ğŸ“ æ›´æ–° README.md...", Colors.YELLOW)

    readme_file = Path("README.md")

    if not readme_file.exists():
        print_color("âŒ README.md ä¸å­˜åœ¨ï¼", Colors.RED)
        return False

    # è¯»å– README.md
    with open(readme_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # åªæ›¿æ¢ç»Ÿè®¡æ•°å­—å’Œæ›´æ–°æ—¶é—´ï¼Œä¿æŒè¡¨æ ¼ç»“æ„ä¸å˜
    # åŒ¹é…æ¨¡å¼ï¼šâ•additions: æ•°å­— â–deletions: æ•°å­— ğŸ–¼ï¸images: æ•°å­—
    pattern = r'(â•additions: )\d+( â–deletions: )\d+( ğŸ–¼ï¸images: )\d+'
    replacement = f'\\g<1>{stats.get("total_additions", 0)}\\g<2>{stats.get("total_deletions", 0)}\\g<3>{stats.get("total_images", 0)}'
    content = re.sub(pattern, replacement, content)

    # åªæ›¿æ¢æ›´æ–°æ—¶é—´ï¼Œä½¿ç”¨ä¸­å›½æ—¶åŒº (UTC+8)
    china_tz = timezone(timedelta(hours=8))
    current_time = datetime.now(china_tz).strftime("%Y-%m-%d %H:%M:%S UTC+8")
    time_pattern = r'(Last updated: )\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}( UTC\+8)?'
    time_replacement = f'\\g<1>{current_time}'
    content = re.sub(time_pattern, time_replacement, content)

    # å†™å› README.md
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print_color("âœ… README.md æ›´æ–°æˆåŠŸï¼", Colors.GREEN)
    print_color(f"   â• å¢åŠ è¡Œæ•°: {stats.get('total_additions', 0)}", Colors.NC)
    print_color(f"   â– åˆ é™¤è¡Œæ•°: {stats.get('total_deletions', 0)}", Colors.NC)
    print_color(f"   ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {stats.get('total_images', 0)}", Colors.NC)
    print_color(f"   ğŸ•’ æ›´æ–°æ—¶é—´: {current_time}", Colors.NC)
    return True


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ GitHub ç»Ÿè®¡')
    parser.add_argument('--no-images', action='store_true', help='ä¸ç»Ÿè®¡å›¾ç‰‡è´¡çŒ®')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…é™¤ç¼“å­˜æ–‡ä»¶')
    args = parser.parse_args()

    print_color("=" * 60, Colors.GREEN)
    print_color("ğŸš€ å¼€å§‹ç”Ÿæˆ GitHub ç»Ÿè®¡...", Colors.GREEN)
    print_color("=" * 60, Colors.GREEN)
    print_color("ğŸ“Š ç»Ÿè®¡é…ç½®:", Colors.YELLOW)
    print_color(f"   - å›¾ç‰‡ç»Ÿè®¡: {'å…³é—­' if args.no_images else 'å¼€å¯'}", Colors.NC)
    if not args.no_images:
        print_color(f"   - ç¼“å­˜ç›®å½•: {CACHE_DIR}", Colors.NC)
    print_color("=" * 60, Colors.GREEN)

    # å¤„ç†æ¸…é™¤ç¼“å­˜
    if args.clear_cache:
        if CACHE_DIR.exists():
            print_color(f"ğŸ—‘ï¸  æ¸…é™¤ç¼“å­˜ç›®å½•: {CACHE_DIR}", Colors.YELLOW)
            shutil.rmtree(CACHE_DIR)
            print_color("âœ… ç¼“å­˜å·²æ¸…é™¤", Colors.GREEN)
        else:
            print_color("â„¹ï¸  ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: " + str(CACHE_DIR), Colors.NC)
        return 0

    # æ£€æŸ¥ TOKEN
    if not TOKEN:
        print_color("âŒ é”™è¯¯: GH_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®", Colors.RED)
        return 1

    # è·å–ä»“åº“åˆ—è¡¨
    repos = get_repos()
    if not repos:
        print_color("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»“åº“", Colors.YELLOW)
        return 1

    # å¤„ç†ä»“åº“
    stats = process_repos(repos, include_images=not args.no_images)

    # æ›´æ–° README.md
    update_readme(stats)

    print_color("=" * 60, Colors.GREEN)
    print_color("âœ… è„šæœ¬æ‰§è¡Œå®Œæˆï¼", Colors.GREEN)
    print_color("=" * 60, Colors.GREEN)
    return 0


if __name__ == "__main__":
    exit(main())
